{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning an unkown distribution where we have control over the sample placement\n",
    "--------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "In the syle of Vorba et al. from \"On-line Learning of Parametric Mixture Models for Light Transport Simulation\" (2014).\n",
    "\n",
    "In the paper, the unkown distribution is the incident radiation (radiance) Li(x). It is modeled by a learned gaussian mixture (GMM).\n",
    "\n",
    "Initially we have no clue about the distribution. We have to start with a very uniform initial guess.\n",
    "The algorithm then alternates between:\n",
    "* Sampling x's from the GMM, and weighting x's by Li, essentially.\n",
    "* Update the GMM to better match Li using the weighted samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import path_guiding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_image(ax, gmm):\n",
    "    t = np.linspace(-1.,1., 100)\n",
    "    x,y = np.meshgrid(t,t)\n",
    "    coord_list = np.vstack((x.ravel(), y.ravel())).T\n",
    "    pdf_vals = gmm.pdf(coord_list)\n",
    "    pdf_vals = np.reshape(pdf_vals, (t.size,t.size))\n",
    "    return ax.imshow(pdf_vals, extent=(-1.,1,1.,-1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm = path_guiding.GMM2d()\n",
    "\n",
    "# nice initialization\n",
    "init_uniform_means_on_cicle = np.array([\n",
    "    [-0.02081824, -0.00203204],\n",
    "    [ 0.4037143 , -0.5633242 ],\n",
    "    [-0.60468113,  0.32800356],\n",
    "    [-0.12180968,  0.6798401 ],\n",
    "    [ 0.6943762 , -0.03451705],\n",
    "    [ 0.4580511 ,  0.52144015],\n",
    "    [-0.63349193, -0.26706135],\n",
    "    [-0.18766472, -0.66355205]\n",
    "])\n",
    "init_means = np.random.normal(loc=0., scale=0.25, size=(8,2)).astype(np.float32)\n",
    "sigma_inv = np.full(8, 10.) #np.random.lognormal(mean=3., sigma=0.2, size=8)\n",
    "init_precisions = np.zeros((8,2,2), dtype=np.float32)\n",
    "init_precisions[:,0,0] = sigma_inv\n",
    "init_precisions[:,1,1] = sigma_inv\n",
    "init_weights = np.full(8, 1./8., dtype=np.float32)\n",
    "\n",
    "gmm.initialize(init_weights, init_uniform_means_on_cicle, init_precisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_set(x, pdf):\n",
    "    # Input: probe positions and associated pdf values\n",
    "    # Output: weights for the EM algo. They are the equivalent of Li/pdf, where Li is the incident radiance.\n",
    "    #         One can think of it as number of photons corrected for the sampling pdf.\n",
    "    #         The intuition behind this correction is the following:\n",
    "    #         Say the pdf is low, implying low sample density. Without the correction, the low pdf value\n",
    "    #         decreases the effective area density of photons $sum Li_i * w_i / n$.\n",
    "    #         If the pdf matches the function Li exactly, then all our weights will be 1. Which is what we want to have in the end.\n",
    "    #         This then also means that the samples are indeed distributed according to Li.\n",
    "    loc1 = (-0.33,0.1)\n",
    "    loc2 = (0.33,-0.1)\n",
    "    locs = test_set.locs = np.array([loc1,loc2])\n",
    "    ws = np.zeros(xs.shape[0])\n",
    "    for l in locs:\n",
    "        scale = 0.25\n",
    "        ws += np.exp(-np.linalg.norm(xs - l[np.newaxis,:], axis=1)**2/scale/scale)\n",
    "    ws /= pdf\n",
    "    return ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "prior_nu = 1.00001; prior_alpha = 2.01; prior_u = 1.e-5; max_iters = 10; maximization_step_every = 50;\n",
    "gmm.initialize(init_weights, init_uniform_means_on_cicle, init_precisions)\n",
    "\n",
    "incremental = path_guiding.GMM2dFitIncremental(\n",
    "    prior_nu = prior_nu, \n",
    "    prior_alpha = prior_alpha, \n",
    "    prior_u = prior_u, \n",
    "    maximization_step_every = maximization_step_every)\n",
    "\n",
    "for iter in range(max_iters):\n",
    "    N = maximization_step_every\n",
    "    xs = gmm.sample(N)\n",
    "    pdf = gmm.pdf(xs)\n",
    "    ws = test_set(xs, pdf)\n",
    "    \n",
    "    incremental.fit(gmm, xs, ws)\n",
    "    fig, ax = pyplot.subplots(1,1, figsize=(10,20))\n",
    "    pdf_image(ax, gmm)\n",
    "    ax.scatter(*xs.T, marker = 'o', s = 40, c = ws, edgecolor = 'w')\n",
    "    ax.scatter(*test_set.locs.T, marker = 'x', s = 100, color = 'r')\n",
    "    ax.scatter(*gmm.means().T, marker='o', s = 40, color='r')\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
